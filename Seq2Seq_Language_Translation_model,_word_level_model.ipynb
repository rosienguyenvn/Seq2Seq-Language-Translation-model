{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "9064fc14",
      "metadata": {
        "id": "9064fc14"
      },
      "source": [
        "# Seq2Seq Language Translation model, word level model\n",
        "\n",
        "### Rosie Nguyen"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "61702b59",
      "metadata": {
        "id": "61702b59"
      },
      "source": [
        "See Datasets: http://www.manythings.org/anki/"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "28064d99",
      "metadata": {
        "id": "28064d99"
      },
      "source": [
        "### Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "00108fd1",
      "metadata": {
        "id": "00108fd1"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import string\n",
        "from string import digits\n",
        "import re\n",
        "from sklearn.utils import shuffle\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import LSTM, Input, Dense,Embedding\n",
        "from keras.models import Model,load_model\n",
        "from keras.preprocessing.text import one_hot\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.models import model_from_json\n",
        "import pickle as pkl\n",
        "import numpy as np\n",
        "from keras.utils.vis_utils import plot_model\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e96b30e1",
      "metadata": {
        "id": "e96b30e1"
      },
      "source": [
        "### Load the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "38e67759",
      "metadata": {
        "id": "38e67759",
        "outputId": "03b397b7-54ff-4007-f9f2-e6d6782497de"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>English</th>\n",
              "      <th>Vietnamese</th>\n",
              "      <th>Others</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Run!</td>\n",
              "      <td>Chạy!</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #9...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Help!</td>\n",
              "      <td>Giúp tôi với!</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #4...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Go on.</td>\n",
              "      <td>Tiếp tục đi.</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Hello!</td>\n",
              "      <td>Chào bạn.</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #3...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Hurry!</td>\n",
              "      <td>Nhanh lên nào!</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #1...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  English      Vietnamese                                             Others\n",
              "0    Run!           Chạy!  CC-BY 2.0 (France) Attribution: tatoeba.org #9...\n",
              "1   Help!   Giúp tôi với!  CC-BY 2.0 (France) Attribution: tatoeba.org #4...\n",
              "2  Go on.    Tiếp tục đi.  CC-BY 2.0 (France) Attribution: tatoeba.org #2...\n",
              "3  Hello!       Chào bạn.  CC-BY 2.0 (France) Attribution: tatoeba.org #3...\n",
              "4  Hurry!  Nhanh lên nào!  CC-BY 2.0 (France) Attribution: tatoeba.org #1..."
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#load raw text data file.\n",
        "df=pd.read_csv('vie.txt',delimiter=\"\\t\", header=None)\n",
        "#name the columns\n",
        "df.columns = ['English', 'Vietnamese', 'Others']\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "52017804",
      "metadata": {
        "id": "52017804"
      },
      "source": [
        "### Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "abfc1427",
      "metadata": {
        "id": "abfc1427"
      },
      "source": [
        "**Remove unnecessary columns, shuffle rows but keep the correlatio between English and Vietnamese columns**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e2993130",
      "metadata": {
        "id": "e2993130",
        "outputId": "bfa25e95-fa6d-4d75-f3b8-e0a874b58da5"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>English</th>\n",
              "      <th>Vietnamese</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6340</th>\n",
              "      <td>Tom has been missing for almost three weeks.</td>\n",
              "      <td>Tom đã mất tích gần ba tuần nay.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5200</th>\n",
              "      <td>You should've come a little earlier.</td>\n",
              "      <td>Đáng lẽ ra bạn nên tới sớm hơn một chút.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>She cried.</td>\n",
              "      <td>Cô ấy đã khóc</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>508</th>\n",
              "      <td>I have two books.</td>\n",
              "      <td>Tôi có hai cuốn sách.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2026</th>\n",
              "      <td>I'm still not buying it.</td>\n",
              "      <td>Tôi vẫn không tin điều đó.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>138</th>\n",
              "      <td>I'm innocent.</td>\n",
              "      <td>Tôi trong sạch!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6023</th>\n",
              "      <td>Do you think Tom really enjoys doing that?</td>\n",
              "      <td>Cậu có nghĩ Tom thực sự thích việc đó không?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2286</th>\n",
              "      <td>I got on the wrong train.</td>\n",
              "      <td>Tớ lên nhầm tàu.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6540</th>\n",
              "      <td>There are a few magazines on the coffee table.</td>\n",
              "      <td>Có vài quyển tạp chí trên cái bàn uống cafe đó.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4355</th>\n",
              "      <td>You're not allowed to camp here.</td>\n",
              "      <td>Anh không được phép cắm trại ở đây.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             English  \\\n",
              "6340    Tom has been missing for almost three weeks.   \n",
              "5200            You should've come a little earlier.   \n",
              "42                                        She cried.   \n",
              "508                                I have two books.   \n",
              "2026                        I'm still not buying it.   \n",
              "138                                    I'm innocent.   \n",
              "6023      Do you think Tom really enjoys doing that?   \n",
              "2286                       I got on the wrong train.   \n",
              "6540  There are a few magazines on the coffee table.   \n",
              "4355                You're not allowed to camp here.   \n",
              "\n",
              "                                           Vietnamese  \n",
              "6340                 Tom đã mất tích gần ba tuần nay.  \n",
              "5200         Đáng lẽ ra bạn nên tới sớm hơn một chút.  \n",
              "42                                      Cô ấy đã khóc  \n",
              "508                             Tôi có hai cuốn sách.  \n",
              "2026                       Tôi vẫn không tin điều đó.  \n",
              "138                                   Tôi trong sạch!  \n",
              "6023     Cậu có nghĩ Tom thực sự thích việc đó không?  \n",
              "2286                                 Tớ lên nhầm tàu.  \n",
              "6540  Có vài quyển tạp chí trên cái bàn uống cafe đó.  \n",
              "4355              Anh không được phép cắm trại ở đây.  "
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#remove column others\n",
        "df= df.drop(columns= 'Others') \n",
        "#shuffle the rows but still keep the correct translation orders\n",
        "df= df.reindex(np.random.permutation(df.index))\n",
        "df.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8dcbf9c8",
      "metadata": {
        "id": "8dcbf9c8"
      },
      "source": [
        "**Text processing: convert to lowercase, remove punctuation, remove whitespaces at the start and end of sentences**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e0ae0fc",
      "metadata": {
        "id": "8e0ae0fc"
      },
      "outputs": [],
      "source": [
        "#text preprocessing\n",
        "eng_lines = df['English'].values\n",
        "viet_lines = df['Vietnamese'].values\n",
        "\n",
        "#convert to lowercase\n",
        "eng_lines = [x.lower() for x in eng_lines]\n",
        "viet_lines = [x.lower() for x in viet_lines]\n",
        "\n",
        "#create remove_punc to remove puntuation\n",
        "def remove_punc(text_list):\n",
        "  table = str.maketrans('', '', string.punctuation)\n",
        "  removed_punc_text = []\n",
        "  for sent in text_list:\n",
        "    sentence = [w.translate(table) for w in sent.split(' ')]\n",
        "    removed_punc_text.append(' '.join(sentence))\n",
        "  return removed_punc_text\n",
        "#use remove_punc on eng and viet\n",
        "eng_lines = remove_punc(eng_lines)\n",
        "viet_lines = remove_punc(viet_lines)\n",
        "\n",
        "# removing the digits from english and vietnamese sentences\n",
        "remove_digits = str.maketrans('', '', digits)\n",
        "removed_digits_eng = []\n",
        "removed_digits_viet = []\n",
        "for sent in eng_lines:\n",
        "  sentence = [w.translate(remove_digits) for w in sent.split(' ')]\n",
        "  removed_digits_eng.append(' '.join(sentence))\n",
        "eng_lines = removed_digits_eng\n",
        "\n",
        "for sent in viet_lines:\n",
        "  sentence = [w.translate(remove_digits) for w in sent.split(' ')]\n",
        "  removed_digits_viet.append(' '.join(sentence))\n",
        "viet_lines = removed_digits_viet\n",
        "\n",
        "#removing the starting and ending whitespaces\n",
        "eng_lines = [x.strip() for x in eng_lines]\n",
        "viet_lines = [x.strip() for x in viet_lines]\n",
        "\n",
        "# Putting the \"<START> \" and \" <END>\" in the vietnamese sentences for effective model training\n",
        "viet_lines = [\"START \" + x + \" END\" for x in viet_lines]\n",
        "#print(viet_lines)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bcd89531",
      "metadata": {
        "id": "bcd89531"
      },
      "source": [
        "**Compute the vocabulary for both English and Vietnamese**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d7dc970b",
      "metadata": {
        "id": "d7dc970b"
      },
      "outputs": [],
      "source": [
        "# Vocabulary of English\n",
        "eng_words=set()\n",
        "for eng in eng_lines:\n",
        "    for word in eng.split():\n",
        "        if word not in eng_words:\n",
        "            eng_words.add(word)\n",
        "\n",
        "# Vocabulary of Vietnamese\n",
        "viet_words=set()\n",
        "for viet in viet_lines:\n",
        "    for word in viet.split():\n",
        "        if word not in viet_words:\n",
        "            viet_words.add(word)\n",
        "#print(eng_words)\n",
        "#print(viet_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "84e0d9a4",
      "metadata": {
        "id": "84e0d9a4",
        "outputId": "4b36e72a-2b55-4f89-ead3-6e7af8bd9166"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Max length of source sequence is 32\n",
            "Max length of target sequence is 41\n"
          ]
        }
      ],
      "source": [
        "# Max Length of source sequence\n",
        "lenght_list=[]\n",
        "for l in eng_lines:\n",
        "    lenght_list.append(len(l.split(' ')))\n",
        "max_length_src = np.max(lenght_list)\n",
        "print('Max length of source sequence is',  max_length_src)\n",
        "# Max Length of target sequence\n",
        "lenght_list=[]\n",
        "for l in viet_lines:\n",
        "    lenght_list.append(len(l.split(' ')))\n",
        "max_length_tar = np.max(lenght_list)\n",
        "print('Max length of target sequence is', max_length_tar)\n",
        "input_words = sorted(list(eng_words))\n",
        "target_words = sorted(list(viet_words))\n",
        "#print(input_words)\n",
        "#print(target_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "915b6bfe",
      "metadata": {
        "id": "915b6bfe",
        "outputId": "869e2810-08e8-42ba-ab2a-df996fc1bf95"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vocab size for source is 3664\n",
            "Vocab size for target is 2319\n"
          ]
        }
      ],
      "source": [
        "# Calculate Vocab size for both source and target\n",
        "num_encoder_tokens = len(eng_words)+1\n",
        "num_decoder_tokens = len(viet_words)+1  \n",
        "\n",
        "print('Vocab size for source is', num_encoder_tokens)\n",
        "print('Vocab size for target is', num_decoder_tokens)\n",
        "# Create word to token dictionary for both source and target\n",
        "input_token_index = dict([(word, i+1) for i, word in enumerate(input_words)])\n",
        "target_token_index = dict([(word, i+1) for i, word in enumerate(target_words)])\n",
        "#print(input_token_index)\n",
        "\n",
        "# Create token to word dictionary for both source and target\n",
        "reverse_input_char_index = dict((i, word) for word, i in input_token_index.items())\n",
        "reverse_target_char_index = dict((i, word) for word, i in target_token_index.items())\n",
        "#print(reverse_input_char_index)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b27ce06b",
      "metadata": {
        "id": "b27ce06b"
      },
      "source": [
        "**Splitting the data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dff91f0f",
      "metadata": {
        "id": "dff91f0f",
        "outputId": "d7f4c6d6-6e2f-4b62-d7c6-2685967dee62"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6802\n",
            "6802\n",
            "756\n",
            "756\n"
          ]
        }
      ],
      "source": [
        "#Splitting the data 90:10 for training: test\n",
        "X = eng_lines\n",
        "Y = viet_lines\n",
        "\n",
        "#Splitting the data 90:10 for training: test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,Y,test_size = 0.1)\n",
        "\n",
        "print(len(X_train))\n",
        "print(len(y_train))\n",
        "print(len(X_test))\n",
        "print(len(y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0ca40b88",
      "metadata": {
        "id": "0ca40b88"
      },
      "source": [
        "**A sentence can be seen as a sequence of either words or characters. For example in case of words, the English sentence \"this is deep learning class\" can be thought of as a sequence of 5 words (‘this’, ‘is’, ‘deep’, ‘learning’, ‘class’). And in case of characters, it can be thought of as a sequence of 18 characters (‘t’, ‘h’, ‘i’, ‘s’, ‘i’, ‘s ‘, ……, ‘s’).**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "40aadc12",
      "metadata": {
        "id": "40aadc12"
      },
      "source": [
        "### Build a word level model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "faf60f5b",
      "metadata": {
        "id": "faf60f5b"
      },
      "source": [
        "The word level language model predict the next word given all previous words in a sequence of data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b64129f3",
      "metadata": {
        "id": "b64129f3"
      },
      "outputs": [],
      "source": [
        "#generator function to load the data in batches\n",
        "def generate_batch(X = X_train, y = y_train, batch_size = 128):\n",
        "    while True:\n",
        "        for j in range(0, len(X), batch_size):\n",
        "            encoder_input_data = np.zeros((batch_size, max_length_src),dtype='float32')\n",
        "            decoder_input_data = np.zeros((batch_size, max_length_tar),dtype='float32')\n",
        "            decoder_target_data = np.zeros((batch_size, max_length_tar, num_decoder_tokens),dtype='float32')\n",
        "            for i, (input_text, target_text) in enumerate(zip(X[j:j+batch_size], y[j:j+batch_size])):\n",
        "                for t, word in enumerate(input_text.split()):\n",
        "                    encoder_input_data[i, t] = input_token_index[word] # encoder input seq\n",
        "                for t, word in enumerate(target_text.split()):\n",
        "                    if t<len(target_text.split())-1:\n",
        "                        decoder_input_data[i, t] = target_token_index[word] # decoder input seq\n",
        "                    if t>0:\n",
        "                        # decoder target sequence (one hot encoded)\n",
        "                        # does not include the START_ token\n",
        "                        # Offset by one timestep\n",
        "                        decoder_target_data[i, t - 1, target_token_index[word]] = 1.\n",
        "            yield([encoder_input_data, decoder_input_data], decoder_target_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "306bee1a",
      "metadata": {
        "id": "306bee1a",
        "outputId": "149c7159-a922-4f7f-d4fd-e16e500b4df3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "encoder_inputs (InputLayer)     [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "decoder_inputs (InputLayer)     [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, None, 256)    937984      encoder_inputs[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, None, 256)    593664      decoder_inputs[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     [(None, 256), (None, 525312      embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   [(None, None, 256),  525312      embedding_1[0][0]                \n",
            "                                                                 lstm[0][1]                       \n",
            "                                                                 lstm[0][2]                       \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, None, 2319)   595983      lstm_1[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 3,178,255\n",
            "Trainable params: 3,178,255\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "latent_dim = 256\n",
        "# Encoder\n",
        "encoder_inputs = Input(shape=(None,),name=\"encoder_inputs\")\n",
        "enc_emb =  Embedding(num_encoder_tokens, latent_dim, mask_zero = True)(encoder_inputs)\n",
        "encoder_lstm = LSTM(latent_dim, return_state=True)\n",
        "encoder_outputs, state_h, state_c = encoder_lstm(enc_emb)\n",
        "\n",
        "# We discard 'encoder_outputs' and only keep the states.\n",
        "encoder_states = [state_h, state_c]\n",
        "\n",
        "# Set up the decoder, using 'encoder_states' as initial state.\n",
        "decoder_inputs = Input(shape=(None,),name=\"decoder_inputs\")\n",
        "dec_emb_layer = Embedding(num_decoder_tokens, latent_dim, mask_zero = True)\n",
        "dec_emb = dec_emb_layer(decoder_inputs)\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _, _ = decoder_lstm(dec_emb, initial_state=encoder_states)\n",
        "\n",
        "# Use a softmax to generate a probability distribution over the target vocabulary for each time step\n",
        "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "# Define the word model that will turn encoder_input_data & decoder_input_data into decoder_target_data\n",
        "word_model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "# Compile the model\n",
        "word_model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['acc'])\n",
        "word_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d73e231a",
      "metadata": {
        "id": "d73e231a",
        "outputId": "87034d33-0bfe-4d2d-afd0-60b484f697c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "('You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) ', 'for plot_model/model_to_dot to work.')\n"
          ]
        }
      ],
      "source": [
        "plot_model(word_model, to_file='train_word_model.png', show_shapes=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a68b44af",
      "metadata": {
        "id": "a68b44af",
        "outputId": "e7b82a08-2a8c-4d16-8d1a-da05bcae36a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "53/53 [==============================] - 69s 1s/step - loss: 1.3066 - acc: 0.1365\n",
            "Epoch 2/100\n",
            "53/53 [==============================] - 83s 2s/step - loss: 1.1858 - acc: 0.1523\n",
            "Epoch 3/100\n",
            "53/53 [==============================] - 62s 1s/step - loss: 1.1405 - acc: 0.1691\n",
            "Epoch 4/100\n",
            "53/53 [==============================] - 74s 1s/step - loss: 1.0916 - acc: 0.1880\n",
            "Epoch 5/100\n",
            "53/53 [==============================] - 120s 2s/step - loss: 1.0421 - acc: 0.2150\n",
            "Epoch 6/100\n",
            "53/53 [==============================] - 118s 2s/step - loss: 0.9916 - acc: 0.2447\n",
            "Epoch 7/100\n",
            "53/53 [==============================] - 162s 3s/step - loss: 0.9546 - acc: 0.2610\n",
            "Epoch 8/100\n",
            "53/53 [==============================] - 92s 2s/step - loss: 0.9173 - acc: 0.2778\n",
            "Epoch 9/100\n",
            "53/53 [==============================] - 97s 2s/step - loss: 0.8833 - acc: 0.2945\n",
            "Epoch 10/100\n",
            "53/53 [==============================] - 114s 2s/step - loss: 0.8507 - acc: 0.3104\n",
            "Epoch 11/100\n",
            "53/53 [==============================] - 134s 3s/step - loss: 0.8220 - acc: 0.3268\n",
            "Epoch 12/100\n",
            "53/53 [==============================] - 72s 1s/step - loss: 0.7893 - acc: 0.3448\n",
            "Epoch 13/100\n",
            "53/53 [==============================] - 55s 1s/step - loss: 0.7624 - acc: 0.3614\n",
            "Epoch 14/100\n",
            "53/53 [==============================] - 56s 1s/step - loss: 0.7350 - acc: 0.3786\n",
            "Epoch 15/100\n",
            "53/53 [==============================] - 52s 976ms/step - loss: 0.7058 - acc: 0.3966\n",
            "Epoch 16/100\n",
            "53/53 [==============================] - 52s 977ms/step - loss: 0.6782 - acc: 0.4140\n",
            "Epoch 17/100\n",
            "53/53 [==============================] - 48s 909ms/step - loss: 0.6518 - acc: 0.4317\n",
            "Epoch 18/100\n",
            "53/53 [==============================] - 67s 1s/step - loss: 0.6266 - acc: 0.4478\n",
            "Epoch 19/100\n",
            "53/53 [==============================] - 60s 1s/step - loss: 0.6008 - acc: 0.4650\n",
            "Epoch 20/100\n",
            "53/53 [==============================] - 50s 939ms/step - loss: 0.5774 - acc: 0.4818\n",
            "Epoch 21/100\n",
            "53/53 [==============================] - 51s 972ms/step - loss: 0.5517 - acc: 0.5008\n",
            "Epoch 22/100\n",
            "53/53 [==============================] - 52s 977ms/step - loss: 0.5282 - acc: 0.5192\n",
            "Epoch 23/100\n",
            "53/53 [==============================] - 54s 1s/step - loss: 0.5061 - acc: 0.5344\n",
            "Epoch 24/100\n",
            "53/53 [==============================] - 54s 1s/step - loss: 0.4850 - acc: 0.5533\n",
            "Epoch 25/100\n",
            "53/53 [==============================] - 53s 1s/step - loss: 0.4635 - acc: 0.5703\n",
            "Epoch 26/100\n",
            "53/53 [==============================] - 56s 1s/step - loss: 0.4437 - acc: 0.5860\n",
            "Epoch 27/100\n",
            "53/53 [==============================] - 56s 1s/step - loss: 0.4228 - acc: 0.6053\n",
            "Epoch 28/100\n",
            "53/53 [==============================] - 62s 1s/step - loss: 0.4026 - acc: 0.6206\n",
            "Epoch 29/100\n",
            "53/53 [==============================] - 55s 1s/step - loss: 0.3832 - acc: 0.6373\n",
            "Epoch 30/100\n",
            "53/53 [==============================] - 50s 951ms/step - loss: 0.3651 - acc: 0.6525\n",
            "Epoch 31/100\n",
            "53/53 [==============================] - 51s 960ms/step - loss: 0.3481 - acc: 0.6693\n",
            "Epoch 32/100\n",
            "53/53 [==============================] - 51s 969ms/step - loss: 0.3314 - acc: 0.6831\n",
            "Epoch 33/100\n",
            "53/53 [==============================] - 52s 982ms/step - loss: 0.3155 - acc: 0.6984\n",
            "Epoch 34/100\n",
            "53/53 [==============================] - 54s 1s/step - loss: 0.2984 - acc: 0.7152\n",
            "Epoch 35/100\n",
            "53/53 [==============================] - 53s 998ms/step - loss: 0.2839 - acc: 0.7282\n",
            "Epoch 36/100\n",
            "53/53 [==============================] - 55s 1s/step - loss: 0.2676 - acc: 0.7461\n",
            "Epoch 37/100\n",
            "53/53 [==============================] - 58s 1s/step - loss: 0.2541 - acc: 0.7580\n",
            "Epoch 38/100\n",
            "53/53 [==============================] - 54s 1s/step - loss: 0.2408 - acc: 0.7700\n",
            "Epoch 39/100\n",
            "53/53 [==============================] - 47s 890ms/step - loss: 0.2276 - acc: 0.7845\n",
            "Epoch 40/100\n",
            "53/53 [==============================] - 54s 1s/step - loss: 0.2141 - acc: 0.7970\n",
            "Epoch 41/100\n",
            "53/53 [==============================] - 52s 987ms/step - loss: 0.2030 - acc: 0.8081\n",
            "Epoch 42/100\n",
            "53/53 [==============================] - 50s 938ms/step - loss: 0.1904 - acc: 0.8219\n",
            "Epoch 43/100\n",
            "53/53 [==============================] - 49s 924ms/step - loss: 0.1799 - acc: 0.8319\n",
            "Epoch 44/100\n",
            "53/53 [==============================] - 49s 924ms/step - loss: 0.1694 - acc: 0.8419\n",
            "Epoch 45/100\n",
            "53/53 [==============================] - 51s 954ms/step - loss: 0.1594 - acc: 0.8535\n",
            "Epoch 46/100\n",
            "53/53 [==============================] - 49s 928ms/step - loss: 0.1499 - acc: 0.8632\n",
            "Epoch 47/100\n",
            "53/53 [==============================] - 53s 993ms/step - loss: 0.1409 - acc: 0.8714\n",
            "Epoch 48/100\n",
            "53/53 [==============================] - 54s 1s/step - loss: 0.1313 - acc: 0.8820\n",
            "Epoch 49/100\n",
            "53/53 [==============================] - 64s 1s/step - loss: 0.1243 - acc: 0.8889\n",
            "Epoch 50/100\n",
            "53/53 [==============================] - 79s 1s/step - loss: 0.1163 - acc: 0.8970\n",
            "Epoch 51/100\n",
            "53/53 [==============================] - 83s 2s/step - loss: 0.1085 - acc: 0.9031\n",
            "Epoch 52/100\n",
            "53/53 [==============================] - 57s 1s/step - loss: 0.1011 - acc: 0.9108\n",
            "Epoch 53/100\n",
            "53/53 [==============================] - 51s 954ms/step - loss: 0.0946 - acc: 0.9185\n",
            "Epoch 54/100\n",
            "53/53 [==============================] - 51s 971ms/step - loss: 0.0889 - acc: 0.9234\n",
            "Epoch 55/100\n",
            "53/53 [==============================] - 52s 986ms/step - loss: 0.0844 - acc: 0.9290\n",
            "Epoch 56/100\n",
            "53/53 [==============================] - 53s 1s/step - loss: 0.0776 - acc: 0.9332\n",
            "Epoch 57/100\n",
            "53/53 [==============================] - 55s 1s/step - loss: 0.0729 - acc: 0.9373\n",
            "Epoch 58/100\n",
            "53/53 [==============================] - 56s 1s/step - loss: 0.0674 - acc: 0.9424\n",
            "Epoch 59/100\n",
            "53/53 [==============================] - 57s 1s/step - loss: 0.0633 - acc: 0.9453\n",
            "Epoch 60/100\n",
            "53/53 [==============================] - 60s 1s/step - loss: 0.0595 - acc: 0.9476\n",
            "Epoch 61/100\n",
            "53/53 [==============================] - 62s 1s/step - loss: 0.0558 - acc: 0.9505\n",
            "Epoch 62/100\n",
            "53/53 [==============================] - 65s 1s/step - loss: 0.0520 - acc: 0.9534\n",
            "Epoch 63/100\n",
            "53/53 [==============================] - 69s 1s/step - loss: 0.0489 - acc: 0.9557\n",
            "Epoch 64/100\n",
            "53/53 [==============================] - 70s 1s/step - loss: 0.0458 - acc: 0.9577\n",
            "Epoch 65/100\n",
            "53/53 [==============================] - 71s 1s/step - loss: 0.0430 - acc: 0.9594\n",
            "Epoch 66/100\n",
            "53/53 [==============================] - 72s 1s/step - loss: 0.0407 - acc: 0.9608\n",
            "Epoch 67/100\n",
            "53/53 [==============================] - 71s 1s/step - loss: 0.0383 - acc: 0.9626\n",
            "Epoch 68/100\n",
            "53/53 [==============================] - 70s 1s/step - loss: 0.0364 - acc: 0.9637\n",
            "Epoch 69/100\n",
            "53/53 [==============================] - 71s 1s/step - loss: 0.0344 - acc: 0.9646\n",
            "Epoch 70/100\n",
            "53/53 [==============================] - 70s 1s/step - loss: 0.0323 - acc: 0.9653\n",
            "Epoch 71/100\n",
            "53/53 [==============================] - 70s 1s/step - loss: 0.0310 - acc: 0.9659\n",
            "Epoch 72/100\n",
            "53/53 [==============================] - 70s 1s/step - loss: 0.0296 - acc: 0.9670\n",
            "Epoch 73/100\n",
            "53/53 [==============================] - 72s 1s/step - loss: 0.0281 - acc: 0.9677\n",
            "Epoch 74/100\n",
            "53/53 [==============================] - 71s 1s/step - loss: 0.0269 - acc: 0.9687\n",
            "Epoch 75/100\n",
            "53/53 [==============================] - 71s 1s/step - loss: 0.0258 - acc: 0.9689\n",
            "Epoch 76/100\n",
            "53/53 [==============================] - 70s 1s/step - loss: 0.0246 - acc: 0.9694\n",
            "Epoch 77/100\n",
            "53/53 [==============================] - 70s 1s/step - loss: 0.0235 - acc: 0.9701\n",
            "Epoch 78/100\n",
            "53/53 [==============================] - 70s 1s/step - loss: 0.0226 - acc: 0.9716\n",
            "Epoch 79/100\n",
            "53/53 [==============================] - 70s 1s/step - loss: 0.0223 - acc: 0.9713\n",
            "Epoch 80/100\n",
            "53/53 [==============================] - 67s 1s/step - loss: 0.0213 - acc: 0.9720\n",
            "Epoch 81/100\n",
            "53/53 [==============================] - 55s 1s/step - loss: 0.0204 - acc: 0.9726\n",
            "Epoch 82/100\n",
            "53/53 [==============================] - 59s 1s/step - loss: 0.0202 - acc: 0.9729\n",
            "Epoch 83/100\n",
            "53/53 [==============================] - 76s 1s/step - loss: 0.0194 - acc: 0.9736\n",
            "Epoch 84/100\n",
            "53/53 [==============================] - 82s 2s/step - loss: 0.0188 - acc: 0.9741\n",
            "Epoch 85/100\n",
            "53/53 [==============================] - 112s 2s/step - loss: 0.0181 - acc: 0.9746\n",
            "Epoch 86/100\n",
            "53/53 [==============================] - 62s 1s/step - loss: 0.0177 - acc: 0.9747\n",
            "Epoch 87/100\n",
            "53/53 [==============================] - 79s 1s/step - loss: 0.0174 - acc: 0.9754\n",
            "Epoch 88/100\n",
            "53/53 [==============================] - 93s 2s/step - loss: 0.0167 - acc: 0.9761\n",
            "Epoch 89/100\n",
            "53/53 [==============================] - 82s 2s/step - loss: 0.0164 - acc: 0.9762\n",
            "Epoch 90/100\n",
            "53/53 [==============================] - 137s 3s/step - loss: 0.0162 - acc: 0.9763\n",
            "Epoch 91/100\n",
            "53/53 [==============================] - 122s 2s/step - loss: 0.0159 - acc: 0.9766\n",
            "Epoch 92/100\n",
            "53/53 [==============================] - 112s 2s/step - loss: 0.0157 - acc: 0.9767\n",
            "Epoch 93/100\n",
            "53/53 [==============================] - 110s 2s/step - loss: 0.0153 - acc: 0.9774\n",
            "Epoch 94/100\n",
            "53/53 [==============================] - 104s 2s/step - loss: 0.0147 - acc: 0.9778\n",
            "Epoch 95/100\n",
            "53/53 [==============================] - 105s 2s/step - loss: 0.0146 - acc: 0.9777\n",
            "Epoch 96/100\n",
            "53/53 [==============================] - 107s 2s/step - loss: 0.0143 - acc: 0.9783\n",
            "Epoch 97/100\n",
            "53/53 [==============================] - 94s 2s/step - loss: 0.0145 - acc: 0.9780\n",
            "Epoch 98/100\n",
            "53/53 [==============================] - 100s 2s/step - loss: 0.0142 - acc: 0.9782\n",
            "Epoch 99/100\n",
            "53/53 [==============================] - 90s 2s/step - loss: 0.0139 - acc: 0.9784\n",
            "Epoch 100/100\n",
            "53/53 [==============================] - 88s 2s/step - loss: 0.0137 - acc: 0.9793\n"
          ]
        }
      ],
      "source": [
        "#Fit the word model\n",
        "train_samples = len(X_train)\n",
        "val_samples = len(X_test)\n",
        "batch_size = 128\n",
        "epochs = 100\n",
        "\n",
        "history= word_model.fit_generator(generator = generate_batch(X_train, y_train, batch_size = batch_size),\n",
        "                    steps_per_epoch = train_samples//batch_size,\n",
        "                    epochs=epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cf39eddc",
      "metadata": {
        "id": "cf39eddc",
        "outputId": "b6231ac5-8f33-4c20-a38c-9ad219a8f562"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of the Word Level Model =  0.9792900681495667\n",
            "Loss of the Word Level Model =  1.3066120147705078\n"
          ]
        }
      ],
      "source": [
        "print(\"Accuracy of the Word Level Model = \",max(history.history[\"acc\"]))\n",
        "print(\"Loss of the Word Level Model = \",max(history.history[\"loss\"]))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "68d6e463",
      "metadata": {
        "id": "68d6e463"
      },
      "source": [
        "**Saving the model into Json**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "51c5f132",
      "metadata": {
        "id": "51c5f132",
        "outputId": "7473180f-0ed1-4481-c412-7255eab40a28"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved word model to disk\n"
          ]
        }
      ],
      "source": [
        "model_json = word_model.to_json()\n",
        "with open(\"model_2.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "# serialize weights to HDF5\n",
        "word_model.save_weights(\"model_weight_5.h5\")\n",
        "print(\"Saved word model to disk\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "565b11a6",
      "metadata": {
        "id": "565b11a6"
      },
      "source": [
        "**Loading the model and weight from Json**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "51aa091a",
      "metadata": {
        "id": "51aa091a"
      },
      "outputs": [],
      "source": [
        "# loading the model architecture and asigning the weights\n",
        "json_file = open('model_2.json', 'r')\n",
        "loaded_model_json = json_file.read()\n",
        "json_file.close()\n",
        "model_loaded = model_from_json(loaded_model_json)\n",
        "# load weights into new model\n",
        "model_loaded.load_weights(\"model_weight_5.h5\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9583cb12",
      "metadata": {
        "id": "9583cb12"
      },
      "source": [
        "**Plot results of accuracy**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea5a91bd",
      "metadata": {
        "id": "ea5a91bd",
        "outputId": "c3c164cb-15bb-43ab-de22-937eaaa9e6bf"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "def plot_history(history,key='acc'):\n",
        "  plt.figure()\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Accuracy')\n",
        "  plt.plot(history.epoch, np.array(history.history['acc']),\n",
        "           label='Train accuracy')\n",
        "  plt.legend()\n",
        "  plt.ylim([0, 1])\n",
        "\n",
        "plot_history(history)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "15dcd977",
      "metadata": {
        "id": "15dcd977"
      },
      "source": [
        "**Plot results of loss**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "70d10206",
      "metadata": {
        "id": "70d10206",
        "outputId": "7289619b-2d66-4dd3-f4b2-a0005476d59c"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "def plot_history2(history):\n",
        "  plt.figure()\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('loss')\n",
        "  plt.plot(history.epoch, np.array(history.history['loss']),\n",
        "           label='Train loss')\n",
        "  plt.legend()\n",
        "  plt.ylim([0, 1.5])\n",
        "\n",
        "plot_history2(history)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5f2379bf",
      "metadata": {
        "id": "5f2379bf"
      },
      "source": [
        "### Prediction using Word Level Model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9b0fcf29",
      "metadata": {
        "id": "9b0fcf29"
      },
      "source": [
        "**Inference Setup**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "03125e3a",
      "metadata": {
        "id": "03125e3a",
        "outputId": "bfc0073f-7135-42da-ca01-84af14a03359"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "encoder_inputs (InputLayer)  [(None, None)]            0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, None, 256)         937984    \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  [(None, 256), (None, 256) 525312    \n",
            "=================================================================\n",
            "Total params: 1,463,296\n",
            "Trainable params: 1,463,296\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Encode the input sequence to get the \"thought vectors\"\n",
        "encoder_model = Model(encoder_inputs, encoder_states)\n",
        "encoder_model.summary()\n",
        "\n",
        "# Decoder setup\n",
        "# Below tensors will hold the states of the previous time step\n",
        "decoder_state_input_h = Input(shape=(latent_dim,))\n",
        "decoder_state_input_c = Input(shape=(latent_dim,))\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "\n",
        "# Get the embeddings of the decoder sequence\n",
        "dec_emb2= dec_emb_layer(decoder_inputs)\n",
        "\n",
        "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
        "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=decoder_states_inputs)\n",
        "decoder_states2 = [state_h2, state_c2]\n",
        "\n",
        "# A dense softmax layer to generate prob dist. over the target vocabulary\n",
        "decoder_outputs2 = decoder_dense(decoder_outputs2)\n",
        "\n",
        "# Final decoder model\n",
        "decoder_model = Model(\n",
        "    [decoder_inputs] + decoder_states_inputs,\n",
        "    [decoder_outputs2] + decoder_states2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "18eace7d",
      "metadata": {
        "id": "18eace7d"
      },
      "outputs": [],
      "source": [
        "# Code to predict the input sentences translation\n",
        "def decode_sequence(input_seq):\n",
        "    # Encode the input as state vectors.\n",
        "    states_value = encoder_model.predict(input_seq)\n",
        "    \n",
        "    # Generate empty target sequence of length 1.\n",
        "    target_seq = np.zeros((1,1))\n",
        "    \n",
        "    # Populate the first character of target sequence with the start character.\n",
        "    target_seq[0, 0] = target_token_index['START']\n",
        "    #print(\"target_seq:=>\",target_seq)\n",
        "    \n",
        "    # Sampling loop for a batch of sequences\n",
        "    # (to simplify, here we assume a batch of size 1).\n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "    \n",
        "    while not stop_condition:\n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
        "        # Sample a token\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
        "        decoded_sentence += ' '+sampled_char\n",
        "        \n",
        "        # Exit condition: either hit max length or find stop token.\n",
        "        if (sampled_char == 'END' or len(decoded_sentence) > 50):\n",
        "            stop_condition = True\n",
        "        \n",
        "        # Update the target sequence (of length 1).\n",
        "        target_seq = np.zeros((1,1))\n",
        "        target_seq[0, 0] = sampled_token_index\n",
        "        \n",
        "        # Update states\n",
        "        states_value = [h, c]\n",
        "    \n",
        "    return decoded_sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "090c3ae7",
      "metadata": {
        "id": "090c3ae7",
        "outputId": "19c3a973-b813-428c-d3b7-93eb74e5a6c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test sentence:  1\n",
            "sentence:  this isnt the first time ive ridden a bicycle\n",
            "original translate: đây không phải là lần đầu tôi đi xe đạp\n",
            "predicted Translate:  ngày qua được sinh ra cho chó vào trang\n",
            "====================================================================================================\n",
            "Test sentence:  2\n",
            "sentence:  do you have a brother\n",
            "original translate: bạn có anhem trai không\n",
            "predicted Translate:  đừng để chúng ta đi ngủ\n",
            "====================================================================================================\n",
            "Test sentence:  3\n",
            "sentence:  i have some time\n",
            "original translate: có có một ít thời gian\n",
            "predicted Translate:  đi bộ cho chuyện đó đang tìm một cách\n",
            "====================================================================================================\n",
            "Test sentence:  4\n",
            "sentence:  he never tells lies\n",
            "original translate: nó không bao giờ nói láo\n",
            "predicted Translate:  anh ấy đang đọc sách\n",
            "====================================================================================================\n",
            "Test sentence:  5\n",
            "sentence:  all of us were silent\n",
            "original translate: tất cả chúng tôi đều đã im lặng\n",
            "predicted Translate:  bạn hãy gọi tôi trong thư để tiết kiệm\n",
            "====================================================================================================\n",
            "Test sentence:  6\n",
            "sentence:  tom demanded an apology\n",
            "original translate: tom yêu cầu một lời xin lỗi\n",
            "predicted Translate:  tôi biết cô ấy ở đâu\n",
            "====================================================================================================\n",
            "Test sentence:  7\n",
            "sentence:  im not sure whats wrong\n",
            "original translate: tôi không rõ là chỗ nào sai\n",
            "predicted Translate:  tôi nghe thấy mày thấy được như thế nào ạ\n",
            "====================================================================================================\n",
            "Test sentence:  8\n",
            "sentence:  i hope that you will like it\n",
            "original translate: hy vọng bạn thích nó\n",
            "predicted Translate:  thật thà là sinh có thể chạy ở trong cuộc sống\n",
            "====================================================================================================\n",
            "Test sentence:  9\n",
            "sentence:  i opened the window\n",
            "original translate: tôi đã mở cửa sổ\n",
            "predicted Translate:  bây giờ là người như vậy\n",
            "====================================================================================================\n",
            "Test sentence:  10\n",
            "sentence:  they still want it\n",
            "original translate: họ vẫn muốn cái đó\n",
            "predicted Translate:  đó đã có một cách hoàn toàn\n",
            "====================================================================================================\n",
            "Test sentence:  11\n",
            "sentence:  i think youre underestimating tom\n",
            "original translate: tôi nghĩ là bạn đang đánh giá thấp tom rồi\n",
            "predicted Translate:  thôi sắp xảy ra\n",
            "====================================================================================================\n",
            "Test sentence:  12\n",
            "sentence:  im afraid i ate too much\n",
            "original translate: tôi lo là tôi đã ăn quá nhiều\n",
            "predicted Translate:  chỉ có thể giúp đỡ một sai lầm của chúng ta\n",
            "====================================================================================================\n",
            "Test sentence:  13\n",
            "sentence:  how do i get to the train station\n",
            "original translate: làm thế nào tôi có thể đi đến ga xe lửa\n",
            "predicted Translate:  một số người đi thể mà chúng tôi thấy\n",
            "====================================================================================================\n",
            "Test sentence:  14\n",
            "sentence:  i bought a house with the money i inherited from my grandfather\n",
            "original translate: tôi đã mua một ngôi nhà bằng tiền thừa kế của ông ngoại tôi\n",
            "predicted Translate:  hầu hết tôi nên đi bộ chúng tôi một chút được\n",
            "====================================================================================================\n",
            "Test sentence:  15\n",
            "sentence:  who did you meet\n",
            "original translate: bạn đã gặp ai thế\n",
            "predicted Translate:  tôi không hút thuốc\n",
            "====================================================================================================\n",
            "Test sentence:  16\n",
            "sentence:  do you need help with something\n",
            "original translate: bạn có cần giúp gì không\n",
            "predicted Translate:  chúng tôi không hút thuốc lá\n",
            "====================================================================================================\n",
            "Test sentence:  17\n",
            "sentence:  hes getting cold feet\n",
            "original translate: anh ấy đang sợ đến co rúm người lại\n",
            "predicted Translate:  con đông giúp bọn quản được\n",
            "====================================================================================================\n",
            "Test sentence:  18\n",
            "sentence:  you people cant stay here\n",
            "original translate: các người không thể ở đây\n",
            "predicted Translate:  phụ nữ có thể là kẻ tranh trước\n",
            "====================================================================================================\n",
            "Test sentence:  19\n",
            "sentence:  please telephone him\n",
            "original translate: xin hãy gọi điện cho ổng\n",
            "predicted Translate:  nó đã làm một hình\n",
            "====================================================================================================\n",
            "Test sentence:  20\n",
            "sentence:  a blind persons hearing is often very acute\n",
            "original translate: khả năng nghe của người mù thường rất tốt\n",
            "predicted Translate:  chúng tôi tìm được một công viên về nhà\n",
            "====================================================================================================\n",
            "Test sentence:  21\n",
            "sentence:  its driving me crazy\n",
            "original translate: cái này làm tôi phát điên mất\n",
            "predicted Translate:  rửa xe này là anh ấy\n",
            "====================================================================================================\n",
            "Test sentence:  22\n",
            "sentence:  are you all right\n",
            "original translate: bạn có làm sao không\n",
            "predicted Translate:  có lẽ là người ngồi máy bay\n",
            "====================================================================================================\n",
            "Test sentence:  23\n",
            "sentence:  tom is a good violinist\n",
            "original translate: tom là một người chơi violon giỏi\n",
            "predicted Translate:  tôi nên không được một nhà\n",
            "====================================================================================================\n",
            "Test sentence:  24\n",
            "sentence:  follow your sisters example\n",
            "original translate: con nên học theo chị con đi\n",
            "predicted Translate:  tôi đang bị rời đi trong vài tuần\n",
            "====================================================================================================\n",
            "Test sentence:  25\n",
            "sentence:  i promised tom id wait until\n",
            "original translate: tôi hứa với tom là tôi sẽ đợi đến  giờ\n",
            "predicted Translate:  có phải cứu một cái máy báo cho con mình\n",
            "====================================================================================================\n",
            "Test sentence:  26\n",
            "sentence:  tom spent fifteen minutes trying to pry open the drawer with a crowbar but he couldnt get it opened\n",
            "original translate: tom đã cố gắng dùng xà beng để mở cái ngăn kéo trong  phút nhưng cuối cùng vẫn không thể mở được\n",
            "predicted Translate:  đi bao nhiêu con giáo nên bị chạy trước khi ăn k\n",
            "====================================================================================================\n",
            "Test sentence:  27\n",
            "sentence:  from there one could see perfectly\n",
            "original translate: có một điểm nhìn hoàn hảo ở đằng đó\n",
            "predicted Translate:  cuộc sống của anh ta chưa\n",
            "====================================================================================================\n",
            "Test sentence:  28\n",
            "sentence:  i wouldnt have been able to finish the job without your help\n",
            "original translate: tôi đã không thể hoàn thành được công việc nếu không nhờ tới sự giúp đỡ của bạn\n",
            "predicted Translate:  sự ngồi trong những người đã bị tuyên tượng là vì\n",
            "====================================================================================================\n",
            "Test sentence:  29\n",
            "sentence:  can i take your bags\n",
            "original translate: tôi mang giỏ dùm bạn nhé\n",
            "predicted Translate:  một anh em ta đang ngủ\n",
            "====================================================================================================\n",
            "Test sentence:  30\n",
            "sentence:  tom isnt sure he wants to get involved\n",
            "original translate: tôm không chắc là anh ấy muốn tham gia\n",
            "predicted Translate:  tôi chỉ thể đi ra ngoài được một ngày mình\n",
            "====================================================================================================\n"
          ]
        }
      ],
      "source": [
        "def tokenizer_(text_data):\n",
        "  tokenizer = Tokenizer()\n",
        "  tokenizer.fit_on_texts(text_data)\n",
        "  return tokenizer\n",
        "\n",
        "tokenizer_input = tokenizer_(X_train)\n",
        "\n",
        "for i in range(30):\n",
        "  sentence = X_test[i]\n",
        "  original_target = y_test[i]\n",
        "  #input_seq = target_token_index.texts_to_sequences([sentence])\n",
        "  input_seq = tokenizer_input.texts_to_sequences([sentence])\n",
        "  pad_sequence = pad_sequences(input_seq, maxlen= 30, padding='post')\n",
        "  predicted_target = decode_sequence(pad_sequence)\n",
        "  print(\"Test sentence: \",i+1)\n",
        "  print(\"sentence: \",sentence)\n",
        "  print(\"original translate:\",original_target[6:-4]) #don't print start and end\n",
        "  print(\"predicted Translate:\",predicted_target[:-4]) ##don't print end\n",
        "  print(\"==\"*50)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "74b708d0",
      "metadata": {
        "id": "74b708d0"
      },
      "source": [
        "### Model Performance"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a3ab1175",
      "metadata": {
        "id": "a3ab1175"
      },
      "source": [
        "The model has a very high accuracy of around 98% but the predicted translation at the end isn't good. \n",
        "The limitation of the simple seq2seq language translation word level model is that it is not able to translate a lengthy sentence that efficiently."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f9bc2404",
      "metadata": {
        "id": "f9bc2404"
      },
      "source": [
        "### Scope of Improvement"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2a5e37e8",
      "metadata": {
        "id": "2a5e37e8"
      },
      "source": [
        "Here are my suggestions:\n",
        "- we can train the model on a large dataset with lots of variation in it.\n",
        "- For lengthy Sentance limitation of it, we can include the Attention Mechanism.\n",
        "- We can try replacing GRU with LSTM and check the performance of the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ee5cfd65",
      "metadata": {
        "id": "ee5cfd65"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.11"
    },
    "colab": {
      "name": "Seq2Seq Language Translation model, word level model",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}